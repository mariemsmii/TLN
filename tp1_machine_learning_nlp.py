# -*- coding: utf-8 -*-
"""TP1-Machine Learning NLP.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_owprzu71Dc5jum9rm05etai7Y-12F1Q

**Step 0 Packages import**
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd #write/Read  ID files
from sklearn.model_selection import train_test_split  #Model selection for splitting dataset
from sklearn.naive_bayes import GaussianNB    #import naive bayes
from sklearn.svm import SVC # SVC() is the Support Vector Machines Classifier
from sklearn.neural_network import MLPClassifier # MLPClassifier us the Neural Network
from sklearn.metrics import confusion_matrix ,  classification_report #import confusion matrix

"""**Step 1 Data Preparation**"""

df = pd.read_csv("/content/drive/MyDrive/BILL/bill_authentication.csv") #read Dataset
df.head() #print the first 5 rows
#pas les deux en meme cellule

df.tail() #print the last 5 rows

df.sample(5) #valeur alea

df.info()  #kol colone  9adech toulha  variable type de variables et est ce que on a des nulls values ou non data missed  1372 non nulll donc el kol null

"""we notice that we have:
4 features: variance 
+ 2 classes 0 et 1
+ 1372 samples
"""

df["Class"].unique() #nombre de classes  fel dataframe fel colonne kima maktouba classe . unique liste qui contient les valeurs unique raj3etli 0 et 0 donc les classes 0 et 1

"""***Step2 Data Split ***"""

#nesna3 men data set train data set val dataset bel fonction train test split 
X= df.drop("Class",axis=1) #axsi nacediw il colone axis=0 accede il lignes
Y= df["Class"]
X.head()

[X_train,X_test,y_train,y_test]=train_test_split(X,Y,test_size=0.2) #20 il taille de test da dataset w thez alea

print("Train dataset size: {}/{}".format(len(X_train),len(Y)))  #y toul el coloone 1372
print("Test dataset size: {}/{}".format(len(X_test),len(Y)))

[X_train1,X_val,y_train1,y_val]=train_test_split(X_train,y_train,test_size=0.2)  # split de doonees

print("Train dataset size: {}/{}".format(len(X_train1),len(y_train)))  #y toul el coloone 1372
print("Test dataset size: {}/{}".format(len(X_val),len(y_train)))

"""****Machine Learning:***"""

gnb=GaussianNB() # gnb is a naive bayes classifier
linear_svm =SVC(kernel='linear') # linear_svm is a Linear Support Vectors   #scm lineaire w non lineaire w 3ana 4 types 
rbf_svm =SVC(kernel='rbf') # rbf_svm is a RBF support vectors
sigmoid_svm =SVC(kernel='sigmoid')# sigmoid support vectors  #intialiser puis lancer le kernelkernel 
ploy_svm =SVC(kernel='poly',degree=2) # Ploynom with degree=2 as support vectors  #defenir archiotecture de neurone activation traja3 mel lineaire il non lineaire mafama chay lineaire en realite perceptron
neural=MLPClassifier(hidden_layer_sizes=(100,20),activation='relu',solver='adam') # neu # (10,20) hidden layers couche 1 fiha 10 neurones w couche 2 fiha 20 neurones activation logistic walla relu

gnb.fit(X_train,y_train) # Train Guassian NB classifier   #trainig apprentissage bel base mta3 trainig
linear_svm.fit(X_train,y_train) # Train SVM
# calculer le proba features prob feature 1 feature2 
rbf_svm.fit(X_train,y_train)
sigmoid_svm.fit(X_train,y_train)
ploy_svm.fit(X_train,y_train)
neural.fit(X_train,y_train) # Train Neural Network - finding the best weight matrix

#Train version 1 base de train zedna  9asamneha il 80 train w 20 test bech manti7ouch fel overfitting
gnb.fit(X_train1,y_train1) # Train Guassian NB classifier
linear_svm.fit(X_train1,y_train1) # Train SVM
rbf_svm.fit(X_train1,y_train1)
sigmoid_svm.fit(X_train1,y_train1)
ploy_svm.fit(X_train1,y_train1)
neural.fit(X_train1,y_train1) # Train Neural Network - finding the best weight matrix

y_nb=gnb.predict(X_test)   #y_pred resultat il 3taha el modele 
y_linear_svm=linear_svm.predict(X_test)
y_rbf_svm=rbf_svm.predict(X_test)
y_ploy_svm=ploy_svm.predict(X_test)
y_sigmoid_svm=sigmoid_svm.predict(X_test)
y_neural=neural.predict(X_test)

#predict version 1
y_nb1=gnb.predict(X_val)
y_linear_svm1=linear_svm.predict(X_val)
y_rbf_svm1=rbf_svm.predict(X_val)
y_ploy_svm1=ploy_svm.predict(X_val)
y_sigmoid_svm1=sigmoid_svm.predict(X_val)
y_neural1=neural.predict(X_val)

print ('************* Peformance Evauation of Naive Bayes **************')
print(confusion_matrix(y_test,y_nb))
print(classification_report(y_test,y_nb))
print ('************* Peformance Evauation of Linear SVM **************')
print(confusion_matrix(y_test,y_linear_svm))
print(classification_report(y_test,y_linear_svm))
print ('************* Peformance Evauation of RBF SVM **************')
print(confusion_matrix(y_test,y_rbf_svm))
print(classification_report(y_test,y_rbf_svm))
print ('************* Peformance Evauation of Sigmoid SVM **************')
print(confusion_matrix(y_test,y_sigmoid_svm))
print(classification_report(y_test,y_sigmoid_svm))
print ('************* Peformance Evauation of Polynomial (2) SVM **************')
print(confusion_matrix(y_test,y_ploy_svm))
print(classification_report(y_test,y_ploy_svm))
print ('************* Peformance Evauation of Neural Network **************')
print(confusion_matrix(y_test,y_neural))
print(classification_report(y_test,y_neural))

# version 1 pour 3 mod√©les
print ('************* Peformance Evauation of Naive Bayes **************')
print(confusion_matrix(y_val,y_nb1))
print(classification_report(y_val,y_nb1))
print ('************* Peformance Evauation of Linear SVM **************')
print(confusion_matrix(y_val,y_linear_svm1))
print(classification_report(y_val,y_linear_svm1))
print ('************* Peformance Evauation of RBF SVM **************')
print(confusion_matrix(y_val,y_rbf_svm1))
print(classification_report(y_val,y_rbf_svm1))
print ('************* Peformance Evauation of Sigmoid SVM **************')
print(confusion_matrix(y_val,y_sigmoid_svm1))
print(classification_report(y_val,y_sigmoid_svm1))
print ('************* Peformance Evauation of Polynomial (2) SVM **************')
print(confusion_matrix(y_val,y_ploy_svm1))
print(classification_report(y_val,y_ploy_svm1))
print ('************* Peformance Evauation of Neural Network **************')
print(confusion_matrix(y_val,y_neural1))
print(classification_report(y_val,y_neural1))